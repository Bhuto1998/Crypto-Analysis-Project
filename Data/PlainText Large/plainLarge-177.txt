ralize across speakers. 
The second dataset is called The Speech Commands. The SC data set is composed of 1s WAVE-files with 16 kHz sample rate containing a single English word each. It is published under Creative Commons BY 4.0 license and contains words spoken by 1864 speakers. In this study, we considered version 0.02 with 105 829 audio files, in which a total of 24 single word commands (Yes, No, Up, Down, Left, Right, On, Off, Stop, Go, Backward, Forward , Follow, Learn, Zero, One, Two, Three, Four, Five, Six, Seven, Eight, Nine) were repeated about five times per speaker, whereas ten auxiliary words (Bed, Bird, Cat, Dog, Happy, House, Marvin, Sheila, Tree, and Wow ) were only repeated approximately once. Partitioning into training, testing, and validation data set was done by a hashing function as described in [43]. For all our purposes, we applied a 30 ms Hann window to the start and end of each waveform. Most importantly, throughout this article, we consider top one classification performance on all 35