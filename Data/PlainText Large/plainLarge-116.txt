many variants.


=== Fully recurrent ===

Fully recurrent neural networks (FRNN) connect the outputs of all neurons to the inputs of all neurons.  This is the most general neural network topology because all other topologies can be represented by setting some connection weights to zero to simulate the lack of connections between those neurons.  The illustration to the right may be misleading to many because practical neural network topologies are frequently organized in "layers" and the drawing gives that appearance.  However, what appears to be layers are, in fact, different steps in time of the same fully recurrent neural network.  The left-most item in the illustration shows the recurrent connections as the arc labeled 'v'.  It is "unfolded" in time to produce the appearance of layers.


=== Elman networks and Jordan networks ===

An Elman network is a three-layer network (arranged horizontally as x, y, and z in the illustration) with the addition of a set of context units (u in the illustration). The midd